{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LA4DS_ch12.ipynb","provenance":[{"file_id":"1qFviZiAMrt-M__X5-4FTU77UKZKCAWnU","timestamp":1643017491021}],"collapsed_sections":[],"authorship_tag":"ABX9TyOXKOxxE3r6iRUJ17RLSQx/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Practical Linear Algebra for Data Science\n","## Mike X Cohen (sincxpress.com)\n","### https://www.oreilly.com/library/view/practical-linear-algebra/9781098120603/\n","\n","#### Code for chapter 12"],"metadata":{"id":"SbGFWGzkd44U"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pq-JEewsnKHm"},"outputs":[],"source":[""]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import pandas as pd\n","\n","# NOTE: these lines define global figure properties used for publication.\n","from IPython import display\n","display.set_matplotlib_formats('svg') # display figures in vector format\n","plt.rcParams.update({'font.size':14}) # set global font size"],"metadata":{"id":"GVWZlfT-nThD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Korean bike rental regression"],"metadata":{"id":"mWvZfl5qjyhT"}},{"cell_type":"code","source":["# Data citation: Sathishkumar V E, Jangwoo Park, and Yongyun Cho. 'Using data mining techniques for bike sharing demand \n","#                prediction in metropolitan city.' Computer Communications, Vol.153, pp.353-366, March, 2020\n","# data source website: https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand\n","\n","# import the data\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00560/SeoulBikeData.csv\"\n","data = pd.read_csv(url,sep=',',encoding='unicode_escape')\n","\n","# let's have a look\n","data"],"metadata":{"id":"g8oFPIQg1BGI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show some data in scatter plots\n","\n","data.plot(x='Date',y='Rented Bike Count',color='k',marker='.',linestyle='none',\n","          figsize=(12,6),ylabel='Rented Bike Count')\n","plt.savefig('Figure_12_1a.png',dpi=300)\n","plt.show()"],"metadata":{"id":"QeRsvLyA1BJH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.plot(x='Date',y='Rainfall(mm)',color='k',marker='.',linestyle='none',\n","          figsize=(12,6),ylabel='Rainfall (mm)');\n","plt.savefig('Figure_12_1b.png',dpi=300)\n","plt.show()"],"metadata":{"id":"1-dB2QI-1BLs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Examine the correlation matrix\n","data.corr()"],"metadata":{"id":"dMTlRjpkRGA3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### show the correlation matrix in an image\n","\n","# only using a few columns\n","columns2use = ['Rented Bike Count','Hour','Temperature(°C)','Rainfall(mm)']\n","colsshort = ['Bikes','Hour','Temp.','Rain'] # for axis labeleing\n","\n","# re-compute the correlation matrix\n","R = data[columns2use].corr()\n","\n","# draw the image\n","plt.figure(figsize=(6,6))\n","plt.imshow(R.values,cmap='gray')\n","plt.xticks(range(4),labels=colsshort)\n","plt.yticks(range(4),labels=colsshort)\n","\n","# text labels\n","for (j,i),num in np.ndenumerate(R.values):\n","  plt.text(i,j,f'{num:.2f}',color=[.8,.8,.8],ha='center',va='center',fontweight='bold',fontsize=15)\n","\n","plt.savefig('Figure_12_02.png',dpi=300)\n","plt.show()"],"metadata":{"id":"iqg7VoNCRarv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# binarize the seasons\n","data.replace(['Spring','Summer', 'Autumn','Winter'],[1,1,0,0], inplace=True)\n","data"],"metadata":{"id":"AJWBg6Kh4Kd6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a design matrix\n","desmat = data[['Rainfall(mm)','Seasons']].to_numpy()\n","\n","# add an intercept\n","desmat = np.append(desmat,np.ones((desmat.shape[0],1)),axis=1)\n","\n","# extract DV\n","y = data[['Rented Bike Count']].to_numpy()\n","\n","\n","# visualize the design matrix\n","plt.figure(figsize=(5,8))\n","plt.imshow(desmat,aspect='auto',vmin=0,vmax=1,origin='lower',interpolation='nearest',cmap='gray')\n","plt.ylabel('Observation')\n","plt.xlabel('Regressor')\n","plt.title('Design matrix')\n","plt.xticks(range(3),labels=['Rainfall','Season','Intercept'])\n","plt.savefig('Figure_12_3a.png',dpi=300)\n","plt.show()"],"metadata":{"id":"1knqrtoQsOEM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot the data\n","plt.figure(figsize=(5,8))\n","\n","# separately for autumn/winter and spring/summer\n","plt.plot(desmat[desmat[:,1]==0,0],y[desmat[:,1]==0],'o',markerfacecolor=(0,0,0,.1),markeredgecolor=(0,0,0,.9),label='Winter')\n","plt.plot(desmat[desmat[:,1]==1,0],y[desmat[:,1]==1],'s',markerfacecolor=(1,0,0,.1),markeredgecolor=(1,0,0,.6),label='Summer')\n","\n","plt.xlabel('Rainfall')\n","plt.ylabel('Bikes rented')\n","plt.legend()\n","plt.savefig('Figure_12_3b.png',dpi=300)\n","plt.show()"],"metadata":{"id":"HUYMtMbW6BkA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run the regression\n","beta = np.linalg.lstsq(desmat,y,rcond=None)\n","beta[0]"],"metadata":{"id":"2pcOSsn06Bdx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## plot some results.\n","\n","# predicted data\n","yHat = desmat@beta[0]\n","\n","# model fit to data (R^2)\n","modelfit = np.corrcoef(y.T,yHat.T)[0,1]**2\n","\n","\n","# and plot\n","plt.figure(figsize=(10,6))\n","plt.plot(y[desmat[:,1]==0],yHat[desmat[:,1]==0],'o',markerfacecolor=(0,0,0,.1),markeredgecolor=(0,0,0,.9),label='Winter')\n","plt.plot(y[desmat[:,1]==1],yHat[desmat[:,1]==1],'s',markerfacecolor=(1,0,0,.1),markeredgecolor=(1,0,0,.6),label='Summer')\n","plt.legend()\n","plt.xlabel('Observed bike counts')\n","plt.ylabel('Predicted bike counts')\n","plt.title(f'Model fit ($R^2$): {modelfit:.3f}')\n","plt.savefig('Figure_12_04.png',dpi=300)\n","plt.show()"],"metadata":{"id":"xzzOY3Wz6Bg8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using statsmodels"],"metadata":{"id":"S8D_zYGxAdi2"}},{"cell_type":"code","source":["import statsmodels.api as sm\n","\n","# extract data (staying with pandas dataframes)\n","desmat_df  = data[['Rainfall(mm)','Seasons']]\n","obsdata_df = data['Rented Bike Count']\n","\n","# create and fit the model\n","desmat_df = sm.add_constant(desmat_df) # must explicitly add an intercept (constant)\n","model = sm.OLS(obsdata_df,desmat_df).fit()\n","print( model.summary() )"],"metadata":{"id":"tl_vgspIJpXN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"FlraVbZjsOHh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Polynomial regression"],"metadata":{"id":"Be1igedLsOLE"}},{"cell_type":"code","source":["x = np.linspace(-2,2,40)\n","maxorder = 3\n","desmat = np.zeros((len(x),maxorder+1))\n","xlab = []\n","\n","\n","_,axs = plt.subplots(1,2,gridspec_kw={'width_ratios':[2,1]}, figsize=(10,6))\n","\n","for i in range(maxorder+1):\n","  axs[0].plot(x,x**i,linewidth=3,label='$y=x^%g$'%i)\n","  desmat[:,i] = x**i\n","  xlab.append( '$x^%g$'%i )\n","\n","axs[0].set(xlim=[-2,2],xlabel='x')\n","axs[0].set(ylim=[-6,6],ylabel='y = f(x)')\n","axs[0].grid()\n","axs[0].legend()\n","axs[0].set_title('Individual regressors')\n","\n","# draw the design matrix\n","axs[1].imshow(desmat,cmap='gray',aspect='auto',vmin=-2,vmax=2,extent=[-.5,maxorder+.5,x[-1],x[0]])\n","axs[1].set(xticks=range(maxorder+1),xticklabels=xlab)\n","axs[1].set_title('Design matrix')\n","\n","plt.savefig('Figure_12_05.png',dpi=300)\n","plt.show()"],"metadata":{"id":"MKk4ZOICHGj5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"KWDE051yI-5N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the data\n","year       = [1534, 1737, 1803, 1928, 1960, 1975, 1987, 2023, 2057, 2100 ]\n","doubleTime = [ 697,  594,  260,  125,   76,   47,   37,   48,   70,  109 ]\n","\n","N = len(year)\n","\n","\n","# plot it\n","plt.figure(figsize=(8,6))\n","plt.plot(year,doubleTime,'ks-',markersize=10)\n","\n","plt.xlabel('Year')\n","plt.ylabel('Doubling time (years)')\n","plt.savefig('Figure_12_06.png',dpi=300)\n","plt.show()\n","\n","## DATA CITATION: \n","#    Max Roser, Hannah Ritchie and Esteban Ortiz-Ospina (2013) - \"World Population Growth\".\n","#    Published online at OurWorldInData.org. Retrieved from: 'https://ourworldindata.org/world-population-growth'\n","#    https://ourworldindata.org/uploads/2019/12/World-population-doubling-time-1.png"],"metadata":{"id":"kk1o9ADWsdAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# design matrix for a 3rd-order polynomial\n","X = np.zeros((N,4))\n","\n","# build the design matrix (note the range \"4\" because of indexing 0-3)\n","for i in range(4): \n","  X[:,i] = np.array(year)**i\n","\n","\n","# converted to ints for your viewing pleasure\n","print(X.astype(int))"],"metadata":{"id":"32JTIEFssdCw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compute the regression coefficients\n","beta = np.linalg.lstsq(X,doubleTime, rcond=None)\n","\n","# and the predicted data\n","yHat = X@beta[0]\n","\n","\n","# plot it\n","plt.figure(figsize=(8,6))\n","plt.plot(year,doubleTime,'ks-',markersize=10,label=r'$y$')\n","plt.plot(year,yHat,'o-',color=[.7,.7,.7],label=r'$\\hat{y}$')\n","\n","plt.legend()\n","plt.xlabel('Year')\n","plt.ylabel('Doubling time (years)')\n","plt.savefig('Figure_12_07.png',dpi=300)\n","plt.show()"],"metadata":{"id":"snNLFGNKsdFb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now using polyfit\n","\n","beta = np.polyfit(year,doubleTime,3)\n","yHat = np.polyval(beta,year)\n","\n","\n","# plot it\n","plt.figure(figsize=(8,6))\n","plt.plot(year,doubleTime,'ks-',markersize=10,label=r'$y$')\n","plt.plot(year,yHat,'o-',color=[.7,.7,.7],label=r'$\\hat{y}$')\n","\n","plt.legend()\n","plt.xlabel('Year')\n","plt.ylabel('Doubling time (years)')\n","plt.show()"],"metadata":{"id":"_IDqC_sisOOT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"vij1goNzz5oa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"LziueBRMz3PF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1 (Bike rental exercises)"],"metadata":{"id":"rhyua3-tECmf"}},{"cell_type":"code","source":["# re-create design matrix and data vector\n","desmat = data[['Rainfall(mm)','Seasons']].to_numpy()\n","desmat = np.append(desmat,np.ones((desmat.shape[0],1)),axis=1)\n","y = data[['Rented Bike Count']].to_numpy()"],"metadata":{"id":"RktFS5rCZ_Zp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# repeat excluding zeros in rainfall\n","\n","desmat_norain = desmat[desmat[:,0]>0,:]\n","y_norain = y[desmat[:,0]>0,:]\n","\n","# plot the data\n","plt.figure(figsize=(10,6))\n","\n","# separately for autumn/winter and spring/summer\n","plt.plot(desmat_norain[desmat_norain[:,1]==0,0],y_norain[desmat_norain[:,1]==0],'o',\n","         markerfacecolor=(0,0,0,.1),markeredgecolor=(0,0,0,.9),label='Winter')\n","plt.plot(desmat_norain[desmat_norain[:,1]==1,0],y_norain[desmat_norain[:,1]==1],'s',\n","         markerfacecolor=(1,0,0,.1),markeredgecolor=(1,0,0,.6),label='Summer')\n","\n","plt.xlabel('Rainfall')\n","plt.ylabel('Bikes rented')\n","plt.title('Data only on rainy days')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"ivhrhvNYAdcw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run the regression (using np's least-squares)\n","beta_norain = np.linalg.lstsq(desmat_norain,y_norain,rcond=None)\n","\n","\n","# predicted data\n","yHat_norain = desmat_norain @ beta_norain[0]\n","\n","# model fit to data (R^2)\n","modelfit = np.corrcoef(y_norain.T,yHat_norain.T)[0,1]**2\n","\n","\n","\n","## plot some results.\n","plt.figure(figsize=(10,6))\n","plt.plot(y_norain[desmat_norain[:,1]==0],yHat_norain[desmat_norain[:,1]==0],'o',\n","         markerfacecolor=(0,0,0,.1),markeredgecolor=(0,0,0,.9),label='Winter')\n","plt.plot(y_norain[desmat_norain[:,1]==1],yHat_norain[desmat_norain[:,1]==1],'s',\n","         markerfacecolor=(1,0,0,.1),markeredgecolor=(1,0,0,.6),label='Summer')\n","\n","plt.legend()\n","plt.xlabel('Observed bike counts')\n","plt.ylabel('Predicted bike counts')\n","plt.title(f'Model fit ($R^2$): {modelfit:.3f}')\n","plt.show()"],"metadata":{"id":"KRzVIazcEFOn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"oqIKwBD6z3R6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2 (Bike rental exercises)"],"metadata":{"id":"7VzBE4n1z3U7"}},{"cell_type":"code","source":["# Create a design matrix\n","desmat = data[['Rainfall(mm)','Temperature(°C)']].to_numpy()\n","desmat = np.append(desmat,np.ones((desmat.shape[0],1)),axis=1)\n","\n","\n","beta = np.linalg.lstsq(desmat,y,rcond=None)\n","yHat = desmat@beta[0]\n","\n","# model fit to data (R^2)\n","modelfit = np.corrcoef(y.T,yHat.T)[0,1]**2\n","\n","# and plot\n","plt.figure(figsize=(10,6))\n","plt.plot(y,yHat,'o',markerfacecolor=(0,0,0,.1),markeredgecolor=(0,0,0,.9))\n","plt.xlabel('Observed bike counts')\n","plt.ylabel('Predicted bike counts')\n","plt.title(f'Model fit ($R^2$): {modelfit:.3f}')\n","plt.savefig('Figure_12_09.png',dpi=300)\n","plt.show()"],"metadata":{"id":"L1QqVjA6NygB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"71Cnn6tMiYZm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3 (multicollinearity)"],"metadata":{"id":"mFya2SSiNylH"}},{"cell_type":"code","source":["# some random linear combination\n","lincombo = 4*desmat[:,0] + .4*desmat[:,1]\n","\n","# Create a design matrix\n","desmatM = data[['Rainfall(mm)','Temperature(°C)']].to_numpy()\n","desmatM = np.append(desmatM,np.ones((desmatM.shape[0],1)),axis=1)\n","\n","# augmented design matrix\n","desmatM = np.append(desmatM,lincombo.reshape(-1,1),axis=1)\n","\n","# size and rank of the design matrix\n","print(f'Design matrix size: {desmatM.shape}')\n","print(f'Design matrix rank: {np.linalg.matrix_rank(desmatM)}')\n","\n","# correlation matrix (note: nan's for intercept b/c no variance)\n","oSettings = np.seterr() # default error handling\n","np.seterr(all='ignore') # ignore warnings for correlation matrices\n","print(f'\\nDesign matrix correlation matrix:')\n","print(np.round(np.corrcoef(desmatM.T),5))\n","np.seterr(**oSettings); # reset the error handling"],"metadata":{"id":"nKyaTzMBOjG-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# A nicer way to print out the correlation matrix using pandas\n","pd.DataFrame(desmatM,columns=['Rain','Temp','Int','Combo']).corr()"],"metadata":{"id":"qT_dS99K9SpD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### using left-inverse\n","\n","# fit the model using the left-inverse\n","X_leftinv = np.linalg.inv(desmatM.T@desmatM) @ desmatM.T\n","# FYI, numpy knowingly \"inverts\" a singular matrix if it's within precision: https://github.com/numpy/numpy/issues/2074\n","\n","# solve for the coefficients and compute R^2\n","beta1 = X_leftinv @ y\n","yHat  = desmatM@beta1\n","\n","# model fit to data (R^2)\n","modelfit1 = np.corrcoef(y.T,yHat.T)[0,1]**2\n","print(modelfit1)"],"metadata":{"id":"VU6T5TEVQmRq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### using numpy's least-squares\n","\n","# fit the model\n","beta2 = np.linalg.lstsq(desmatM,y,rcond=None)\n","yHat  = desmatM@beta2[0]\n","\n","# model fit to data (R^2)\n","modelfit2 = np.corrcoef(y.T,yHat.T)[0,1]**2\n","print(modelfit2)"],"metadata":{"id":"QyzxivC5PwKE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### using statsmodels\n","\n","# convert the design matrix into a pandas dataframe\n","desmat_df = pd.DataFrame(desmatM)\n","\n","# create and fit the model\n","desmat_df = sm.add_constant(desmat_df)\n","model = sm.OLS(obsdata_df,desmat_df).fit()\n","\n","\n","beta3 = model.params.values\n","modelfit3 = model.rsquared"],"metadata":{"id":"1cgvUg9xOjJY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print all to compare\n","\n","print('MODEL FIT TO DATA:')\n","print(f'  Left-inverse: {modelfit1:.4f}')\n","print(f'  np lstsqr   : {modelfit2:.4f}')\n","print(f'  statsmodels : {modelfit3:.4f}')\n","\n","print(' ')\n","print('BETA COEFFICIENTS:')\n","print(f'  Left-inverse: {np.round(beta1.T,3)}')\n","print(f'  np lstsqr   : {np.round(beta2[0].T,3)}')\n","print(f'  statsmodels : {np.round(beta3.T,3)}')"],"metadata":{"id":"-32MU187Nynu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"eG5XpXjple2F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 4 (regularization)"],"metadata":{"id":"mI3Q49rrmB6C"}},{"cell_type":"code","source":["# regularization proportion\n","gamma = .01\n","\n","# gamma times the norm\n","gamnorm = gamma * np.linalg.norm(desmatM,'fro')**2\n","\n","# inverse of (X'X+lI)\n","leftinv = np.linalg.inv(desmatM.T@desmatM + gamnorm*np.eye(desmatM.shape[1]))\n","\n","# print results\n","print(f\"inv(X'X + {gamma}*I) size: {leftinv.shape}\")\n","print(f\"inv(X'X + {gamma}*I) rank: {np.linalg.matrix_rank(leftinv)}\")"],"metadata":{"id":"6zggvtkDsJnH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Note about this code:\n","# Exercise 7 of chapter 13 relies on this code. Use the following toggle when you're on chapter 13 :)\n","I_am_reading_chapter_13 = False\n","\n","\n","# range of gamma parameters\n","gs = np.linspace(0,.2,40)\n","\n","# initialize r2 vector\n","r2s  = np.zeros(gs.shape)\n","r2sM = np.zeros(gs.shape) # the 'M' is for multicollinearity\n","\n","\n","# loop over gammas\n","for i in range(len(gs)):\n","\n","  # create lambda\n","  l = gs[i]*np.linalg.norm(desmat,'fro')**2\n","\n","  if I_am_reading_chapter_13: # exercise 13.7\n","    l = gs[i]*np.mean(np.linalg.eig(desmat.T@desmat)[0])\n","\n","  # compute left-inverse\n","  leftinv = np.linalg.inv(desmat.T@desmat + l*np.eye(desmat.shape[1])) @ desmat.T\n","  \n","  # compute beta and predicted data\n","  b = leftinv @ y\n","  yHat = desmat@b\n","\n","  # model fit to data\n","  r2s[i] = np.corrcoef(y.T,yHat.T)[0,1]**2\n","\n","\n","  ### repeat for the multicollinear model (condensed for convenience)\n","  l       = gs[i]*np.linalg.norm(desmatM,'fro')**2\n","  if I_am_reading_chapter_13: # exercise 13.6\n","    l     = gs[i]*np.mean(np.linalg.eig(desmatM.T@desmatM)[0])\n","  leftinv = np.linalg.inv(desmatM.T@desmatM + l*np.eye(desmatM.shape[1])) @ desmatM.T\n","  b       = leftinv @ y\n","  yHat    = desmatM@b\n","  r2sM[i] = np.corrcoef(y.T,yHat.T)[0,1]**2\n","\n","\n","\n","# plot the results\n","plt.figure(figsize=(8,5))\n","plt.plot(gs,r2s,'ks-',linewidth=2,label='Original')\n","plt.plot(gs,r2sM,'o-',linewidth=2,label='Multicol.',color=[.7,.7,.7])\n","plt.xlabel('Regularization $\\lambda$')\n","plt.ylabel('$R^2$ fit to data')\n","plt.ylim([.27,.32])\n","plt.legend()\n","plt.savefig('Figure_12_10.png',dpi=300)\n","plt.show()"],"metadata":{"id":"hlmzB_MZnHdF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"oSnJv8KQ4lH6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 5 (polynomial)"],"metadata":{"id":"shugTz0qsOXN"}},{"cell_type":"code","source":["# plot it\n","_,axs = plt.subplots(2,5,figsize=(14,5))\n","axs = axs.flatten()\n","\n","\n","for oi in range(N):\n","  beta = np.polyfit(year,doubleTime,oi)\n","  yHat = np.polyval(beta,year)\n","\n","  # plot\n","  axs[oi].plot(year,doubleTime,'ks-',markersize=10)\n","  axs[oi].plot(year,yHat,'o--',color=[.7,.7,.7])\n","  axs[oi].set(xticks=[], yticks=[])\n","  axs[oi].set_title('Order=%g' %oi)\n","\n","plt.tight_layout()\n","plt.savefig('Figure_12_11.png',dpi=300)\n","plt.show()"],"metadata":{"id":"UGU_K4qLz5dv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"JiXKiVqhsOaB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 6 (grid search)"],"metadata":{"id":"0c2ueLP3uz5b"}},{"cell_type":"code","source":["# NOTE: data and model from the previous chapter\n","numcourses = [13,4,12,3,14,13,12,9,11,7,13,11,9,2,5,7,10,0,9,7]\n","happiness  = [70,25,54,21,80,68,84,62,57,40,60,64,45,38,51,52,58,21,75,70]\n","\n","# design matrix\n","X = np.hstack((np.ones((20,1)),np.array(numcourses,ndmin=2).T))\n","beta = np.linalg.lstsq(X,happiness,rcond=None)[0]"],"metadata":{"id":"QbDG-cjnjc6Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the number of steps for each parameter\n","gridResolution = 100\n","\n","\n","# specify intercepts and slopes to test\n","intercepts = np.linspace(0,80,gridResolution)\n","slopes = np.linspace(0,6,gridResolution)\n","\n","# initialize output matrix\n","SSEs = np.zeros((len(intercepts),len(slopes)))\n","\n","\n","# for-loops over parameters\n","for inti in range(len(intercepts)):\n","  for slopei in range(len(slopes)):\n","\n","    # model-predicted data\n","    yHat = X @ np.array([intercepts[inti],slopes[slopei]]).T\n","\n","    # sum of squared errors\n","    SSEs[inti,slopei] = np.sum((yHat-happiness)**2)\n","\n","\n","# find empirical minimum\n","i,j = np.unravel_index( np.argmin(SSEs),SSEs.shape )\n","empIntercept,empSlope = intercepts[i], slopes[j]\n","\n","\n","# plot the error landscape with empirical minimum\n","plt.figure(figsize=(6,6))\n","plt.imshow(SSEs,vmin=2000,vmax=3000,\n","           extent=[slopes[0],slopes[-1],intercepts[0],intercepts[-1]],\n","           origin='top',aspect='auto',cmap='gray')\n","plt.plot(empSlope,empIntercept,'o',color=[1,.4,.4],markersize=12,label='Grid search minimum')\n","plt.plot(beta[1],beta[0],'x',color=[.4,.7,1],markeredgewidth=4,markersize=10,label='Analytic solution')\n","plt.colorbar()\n","plt.xlabel('Slope')\n","plt.ylabel('Intercept')\n","plt.title('SSE (fit of model to data)')\n","plt.legend()\n","plt.savefig('Figure_12_08.png',dpi=300)\n","plt.show()\n","\n","# print out the results\n","print('Analytic result: ')\n","print(f'   Intercept: {beta[0]:.2f}, slope: {beta[1]:.2f}')\n","print(' ')\n","print('Empirical result: ')\n","print(f'   Intercept: {empIntercept:.2f}, slope: {empSlope:.2f}')"],"metadata":{"id":"xkuycEkO2k3N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"sGP19orVryIw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 7 (grid search)"],"metadata":{"id":"J24lseSLryjZ"}},{"cell_type":"code","source":["# the number of steps for each parameter\n","gridResolution = 20\n","\n","\n","# specify intercepts and slopes to test\n","intercepts = np.linspace(0,80,gridResolution)\n","slopes = np.linspace(0,6,gridResolution)\n","\n","# initialize output matrix\n","r2 = np.zeros((len(intercepts),len(slopes)))\n","allYhat = np.zeros((len(intercepts),len(slopes),len(happiness)))\n","\n","# for-loops over parameters\n","for inti in range(len(intercepts)):\n","  for slopei in range(len(slopes)):\n","\n","    # model-predicted data\n","    yHat = X @ np.array([intercepts[inti],slopes[slopei]]).T\n","\n","    # R2 model fit\n","    r2[inti,slopei] = np.corrcoef(yHat,happiness)[0,1]**2\n","    \n","    # store all predicted data values\n","    allYhat[inti,slopei,:] = yHat\n","\n","\n","# find empirical minimum\n","i,j = np.unravel_index( np.argmax(r2),r2.shape )\n","empIntercept,empSlope = intercepts[i], slopes[j]\n","\n","\n","# plot the error landscape with empirical minimum\n","plt.figure(figsize=(6,6))\n","plt.imshow(r2,vmin=0,vmax=.5,\n","           extent=[slopes[0],slopes[-1],intercepts[0],intercepts[-1]],\n","           origin='top',aspect='auto',cmap='gray')\n","plt.plot(empSlope,empIntercept,'o',color=[1,.4,.4],markersize=12,label='Grid search minimum')\n","plt.plot(beta[1],beta[0],'x',color=[.4,.7,1],markeredgewidth=4,markersize=10,label='Analytic solution')\n","plt.colorbar()\n","plt.xlabel('Slope')\n","plt.ylabel('Intercept')\n","plt.title('$R^2$ fit of model to data')\n","plt.legend()\n","plt.show()\n","\n","# print out the results\n","print('Analytic result: ')\n","print(f'   Intercept: {beta[0]:.2f}, slope: {beta[1]:.2f}')\n","print(' ')\n","print('Empirical result: ')\n","print(f'   Intercept: {empIntercept:.2f}, slope: {empSlope:.2f}')"],"metadata":{"id":"LnO4XR0b2nAg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Why doesn't this approach work? \n","# Let's start by plotting predicted data for different parameters.\n","\n","_,axs = plt.subplots(1,2,figsize=(14,5))\n","\n","axs[0].plot(allYhat[5,:,:].T,'s-',markersize=3)\n","axs[0].plot(happiness,'ko-',linewidth=4,label='True observations')\n","axs[0].set_xlabel('Data index (surveyed student)')\n","axs[0].set_ylabel('Happiness rating')\n","axs[0].set_title('Each line is a different slope')\n","axs[0].legend()\n","\n","axs[1].plot(allYhat[:,5,:].T,'s-',markersize=3)\n","axs[1].plot(happiness,'ko-',linewidth=4,label='True observations')\n","axs[1].set_xlabel('Data index (surveyed student)')\n","axs[1].set_ylabel('Happiness rating')\n","axs[1].set_title('Each line is a different intercept')\n","axs[1].legend()\n","\n","plt.show()\n","\n","# The plots show that the predicted values are quite similar for different parameter pairs.\n","# Recall that data are mean-centered in the correlation formula. In fact, we can re-plot these\n","# predicted data after mean-centering, i.e., the way a correlation would see the data. \n","# Move on to the next cell..."],"metadata":{"id":"Y_Do_j3d2nDP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The plots here are the same as above, but all data have been mean-centered.\n","\n","_,axs = plt.subplots(1,2,figsize=(14,5))\n","\n","axs[0].plot(allYhat[5,:,:].T - np.mean(allYhat[5,:,:].T,axis=0),'s-',markersize=3)\n","axs[0].plot(happiness-np.mean(happiness),'ko-',linewidth=4,label='True observations')\n","axs[0].set_xlabel('Data index (surveyed student)')\n","axs[0].set_ylabel('Happiness rating')\n","axs[0].set_title('Each line is a different slope')\n","axs[0].legend()\n","\n","axs[1].plot(allYhat[:,5,:].T - np.mean(allYhat[:,5,:].T,axis=0),'s-',markersize=3)\n","axs[1].plot(happiness-np.mean(happiness),'ko-',linewidth=4,label='True observations')\n","axs[1].set_xlabel('Data index (surveyed student)')\n","axs[1].set_ylabel('Happiness rating')\n","axs[1].set_title('Each line is a different intercept')\n","axs[1].legend()\n","\n","plt.show()\n","\n","# All of the intercept terms have collapsed into a single line -- not surprising considering that\n","# the intercept term of a linear model _is_ simply a mean offset.\n","# \n","# The conclusion of this investigation is that R^2 is not a useful model fit metric in this example.\n","# Of course, that doesn't mean it never a useful model; instead, it means that you need to think\n","# carefully about the metrics you use to evaluate model fit to data."],"metadata":{"id":"Pb9kGvHFtlEM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"f7iJ7Z53uGoq"},"execution_count":null,"outputs":[]}]}